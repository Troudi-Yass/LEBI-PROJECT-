{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase 3 - Modélisation & Enrichissement Machine Learning\n",
                "\n",
                "Cette phase exploite directement le fichier `hellowork_preprocessed.csv` issu de ta Phase 2."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.1 Objectifs BI & ML\n",
                "\n",
                "*   Identifier automatiquement des **groupes de métiers / compétences**\n",
                "*   Enrichir le dataset avec des **clusters interprétables**\n",
                "*   Classer les offres selon un **niveau de salaire** exploitable analytiquement\n",
                "*   Préparer les résultats pour une **visualisation interactive**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.2 Chargement des données"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "df = pd.read_csv(\"hellowork_preprocessed.csv\")\n",
                "# Preserve Date column\n",
                "if 'Publication_Date' in df.columns:\n",
                "    df['Publication_Date'] = pd.to_datetime(df['Publication_Date'])\n",
                "\n",
                "print(df.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.3 Clustering NLP (Descriptions d'offres)\n",
                "\n",
                "### a) Vectorisation TF-IDF"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "\n",
                "tfidf = TfidfVectorizer(max_features=500)\n",
                "# On s'assure que Description_Clean est bien de type string\n",
                "X_text = tfidf.fit_transform(df['Description_Clean'].astype(str))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### b) Modélisation par NMF (Non-negative Matrix Factorization)\n",
                "\n",
                "Nous remplaçons ici KMeans par **NMF**, un algorithme souvent plus performant pour l'extraction de thématiques (Topic Modeling) sur du texte."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.decomposition import NMF\n",
                "\n",
                "# On choisit 5 thématiques (clusters)\n",
                "nmf = NMF(n_components=5, random_state=42)\n",
                "\n",
                "# W contient la matrice Documents x Topics\n",
                "W = nmf.fit_transform(X_text)\n",
                "\n",
                "# On assigne chaque offre au topic dominant (celui avec le score le plus élevé)\n",
                "df['Job_Cluster'] = W.argmax(axis=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### c) Interprétation des clusters (Thématiques)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "terms = tfidf.get_feature_names_out()\n",
                "# Pour NMF, nmf.components_ contient la matrice Topics x Termes\n",
                "for i in range(5):\n",
                "    center_terms = nmf.components_[i].argsort()[-10:]\n",
                "    print(f\"Cluster {i}:\", [terms[t] for t in center_terms])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.4 Classification - Niveau de salaire\n",
                "\n",
                "### a) Création de la cible"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "median_salary = df['Salary_Clean'].median()\n",
                "df['High_Salary'] = (df['Salary_Clean'] >= median_salary).astype(int)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### b) Entraînement du modèle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import classification_report\n",
                "\n",
                "features = df[['Sector_Encoded', 'Contract_Encoded']].fillna(0)\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    features, df['High_Salary'], test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "model = LogisticRegression(max_iter=1000)\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "print(classification_report(y_test, model.predict(X_test)))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### c) Ajout des prédictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['Salary_Class_Pred'] = model.predict(features)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.5 Sauvegarde dataset enrichi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.to_csv(\"hellowork_ml_enriched.csv\", index=False)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}