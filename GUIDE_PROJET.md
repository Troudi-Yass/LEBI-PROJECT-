# üìò Guide du Projet LEBI - Analyse du March√© de l'Emploi

Ce guide explique le fonctionnement technique et fonctionnel des 4 phases du projet.
Le projet est disponible en deux formats : **Notebooks Jupyter** (`.ipynb`) pour l'exploration et **Scripts Python** (`.py`) pour l'automatisation.

---

## üèóÔ∏è Phase 1 : Extraction des Donn√©es (Web Scraping)
**Objectif** : R√©cup√©rer les offres d'emploi depuis le site **Hellowork**.

*   **Fichiers** : `LEBI_Scrapping.py` (ou `.ipynb`)
*   **Technologie** : `Selenium` (Chrome WebDriver)
*   **Fonctionnement** :
    1.  Le script parcourt une liste de **26 secteurs** d'activit√©.
    2.  Pour chaque secteur, il navigue sur les pages de r√©sultats (jusqu'√† 10 pages).
    3.  Il extrait : Titre, Entreprise, Localisation, Contrat, Salaire, Description, URL.
*   **R√©sultat** : Cr√©e un fichier brut `hellowork_final_sectors_data.csv`.

---

## üßπ Phase 2 : Pr√©paration des Donn√©es (ETL)
**Objectif** : Nettoyer et structurer les donn√©es brutes pour le Machine Learning.

*   **Fichiers** : `LEBI_ETL.py` (ou `.ipynb`)
*   **Technologie** : `Pandas`, `NLTK`, `Scikit-learn`
*   **Traitements** :
    1.  **Nettoyage** : Suppression des doublons et des valeurs manquantes.
    2.  **Date (Simulation)** : G√©n√©ration de dates de publication fictives (analyse temporelle) car non scrap√©es en Phase 1.
    3.  **Salaires** : Conversion des textes (ex: "30k-40k") en valeurs num√©riques (moyenne mensuelle).
    4.  **NLP** : Nettoyage du texte des descriptions (minuscules, retrait ponctuation/stopwords).
    5.  **Encodage** : Transformation des variables Cat√©gorielles (Secteur, Contrat) en chiffres.
*   **R√©sultat** : Cr√©e le fichier propre `hellowork_preprocessed.csv`.

---

## ü§ñ Phase 3 : Mod√©lisation & Enrichissement ML
**Objectif** : Cr√©er de la valeur ajout√©e gr√¢ce √† l'Intelligence Artificielle.

*   **Fichiers** : `Phase3_Modelisation.py` (ou `.ipynb`)
*   **Technologie** : `Scikit-learn` (NMF, LogisticRegression)
*   **Algorithmes** :
    1.  **Clustering (NMF)** : Analyse les descriptions pour regrouper les offres en **5 th√©matiques m√©tiers** (Topics). *Utilise NMF au lieu de KMeans pour une meilleure interpr√©tation textuelle.*
    2.  **Classification (Logistic Regression)** : Pr√©dit si une offre est "Haut Salaire" ou "Bas Salaire" en fonction du secteur et du contrat.
*   **R√©sultat** : Cr√©e le fichier enrichi `hellowork_ml_enriched.csv` contenant les clusters et les pr√©dictions.

---

## üìä Phase 4 : Dashboard Interactif
**Objectif** : Visualiser les donn√©es et les r√©sultats des mod√®les.

*   **Fichiers** : `Phase4_Dashboard.py` (ou `.ipynb`)
*   **Technologie** : `Dalsh` (Plotly)
*   **Fonctionnalit√©s** :
    1.  **Filtres** : S√©lection dynamique par secteur d'activit√©.
    2.  **Graphiques** :
        *   R√©partition des Clusters M√©tiers (Histogramme).
        *   Classification Salariale (Barres).
        *   **NOUVEAU** : Analyse Temporelle (Courbe des offres par semaine).
*   **Acc√®s** : Lancez le script et ouvrez http://127.0.0.1:8050/ dans votre navigateur.

---

## üöÄ Comment lancer le projet complet ?

**Option A (Recommand√©e) : Lancement Automatique**
Lancez tout le pipeline en une seule commande :
```bash
python main.py
```

**Option B : Lancement Manuel (√©tape par √©tape)**
Ex√©cutez les commandes suivantes dans votre terminal, dans l'ordre :

```bash
# 1. Scraping (Long - peut √™tre saut√© si vous avez d√©j√† les donn√©es)
python LEBI_Scrapping.py

# 2. Nettoyage et pr√©paration (Inclus la g√©n√©ration de dates)
python LEBI_ETL.py

# 3. Intelligence Artificielle (Clustering & Classification)
python Phase3_Modelisation.py

# 4. Lancement de l'application Dashboard
python Phase4_Dashboard.py
```
