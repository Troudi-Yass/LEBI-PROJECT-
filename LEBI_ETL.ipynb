{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf75f74f",
   "metadata": {},
   "source": [
    "## Phase 2 – Data Preparation (ETL)\n",
    "\n",
    "Phase 2 focuses on **cleaning, transforming, and structuring** the raw job offer data collected in Phase 1, producing a **machine-learning-ready dataset** for Phase 3 modeling and dashboard visualization.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Cleaning\n",
    "- Remove duplicates (`Job_Title + Company + Location + URL`).  \n",
    "- Handle missing values for `Salary`, `Contract`, `Experience_Level`, etc.  \n",
    "- Strip whitespace, line breaks, and HTML artifacts from textual fields (`Job_Title`, `Description`).  \n",
    "\n",
    "---\n",
    "\n",
    "### 2. Standardization\n",
    "- Convert `Salary` to a **numerical format** (annual salary in EUR), handle ranges and units.  \n",
    "- Standardize `Publication_Date` as datetime objects and optionally compute job age.  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. Feature Extraction\n",
    "- Extract keywords/skills from `Description` using **text preprocessing**: lowercase, remove stopwords, lemmatization/stemming, punctuation removal.  \n",
    "- Prepare **text vectors** (TF-IDF or CountVectorizer) for ML clustering in Phase 3.  \n",
    "\n",
    "---\n",
    "\n",
    "### 4. Categorical Encoding\n",
    "- Encode categorical fields (`Contract_Type`, `Location`, `Sector`, `Experience_Level`) for ML:\n",
    "  - One-hot encoding or label encoding.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Validation & Saving\n",
    "- Check for missing or malformed fields, salary outliers, and consistency of sectors.  \n",
    "- Save the cleaned dataset as `hellowork_cleaned.csv` (UTF-8 encoded) for Phase 3.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Phase Outcome\n",
    "- Dataset is **clean, structured, and standardized**  \n",
    "- Textual and categorical features are **ML-ready**  \n",
    "- Missing or inconsistent values are handled  \n",
    "- Data is prepared for **clustering, classification, and dashboard visualization**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a948e2",
   "metadata": {},
   "source": [
    "### **Libraries Used in Phase 2 – Data Preparation (ETL)**\n",
    "\n",
    "### **1. pandas**\n",
    "- Core library for loading, cleaning, and manipulating datasets.\n",
    "- Used for reading CSVs, handling missing values, removing duplicates, and saving cleaned datasets.\n",
    "\n",
    "### **2. numpy**\n",
    "- Supports numerical operations and handling missing values (NaNs).\n",
    "- Useful for calculations like salary averages or job age.\n",
    "\n",
    "### **3. re (Regular Expressions)**\n",
    "- Handles text pattern matching and extraction.\n",
    "- Used to clean and standardize salary fields or remove unwanted characters from text.\n",
    "\n",
    "### **4. string**\n",
    "- Provides constants for common text operations (e.g., punctuation).\n",
    "- Helps in removing punctuation from job descriptions.\n",
    "\n",
    "### **5. nltk (Natural Language Toolkit)**\n",
    "- Library for text preprocessing and NLP tasks.\n",
    "- Used for stopwords removal, tokenization, and preparing text for vectorization.\n",
    "\n",
    "### **6. sklearn.feature_extraction.text.TfidfVectorizer**\n",
    "- Converts text data (job descriptions) into numeric feature vectors.\n",
    "- Essential for clustering and classification in Phase 3.\n",
    "\n",
    "### **7. sklearn.preprocessing.OneHotEncoder**\n",
    "- Converts categorical variables (e.g., Sector, Contract) into numeric one-hot encoded features for ML.\n",
    "\n",
    "### **8. sklearn.preprocessing.LabelEncoder**\n",
    "- Converts categorical labels into numeric form if needed.\n",
    "\n",
    "### **9. datetime**\n",
    "- Handles date operations.\n",
    "- Useful for converting publication dates and calculating job age in days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddffd51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Basic Data Handling ---\n",
    "import pandas as pd          # For loading, cleaning, and manipulating datasets\n",
    "import numpy as np           # For numerical operations and handling NaNs\n",
    "# --- File / Path Utilities ---\n",
    "from pathlib import Path     # For filesystem-safe path handling\n",
    "import os                    # For interacting with the filesystem\n",
    "# --- Web/Regex/Text Processing ---\n",
    "import re                    # For regular expressions (cleaning salaries, text)\n",
    "import string                # For punctuation removal in text\n",
    "import nltk                  # Natural Language Toolkit for text processing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')   # Download the stopwords corpus\n",
    "nltk.download('punkt')       # Download tokenizer models\n",
    "nltk.download('wordnet')     # Download WordNet lemmatizer data\n",
    "# --- Machine Learning / Preprocessing ---\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Convert text to numeric features\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # Bag-of-words representation\n",
    "from sklearn.preprocessing import OneHotEncoder              # Encode categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder               # Label encoding if needed\n",
    "from sklearn.preprocessing import StandardScaler             # Scale numeric features\n",
    "from sklearn.model_selection import train_test_split         # Train/validation splits\n",
    "# --- Date/Time Handling ---\n",
    "import datetime              # For working with publication dates and job age\n",
    "# --- Visualization & Progress ---\n",
    "import matplotlib.pyplot as plt  # Quick exploratory plots\n",
    "import seaborn as sns            # Statistical visualizations\n",
    "from tqdm import tqdm            # Progress bars for loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49699646",
   "metadata": {},
   "source": [
    "## Step 1 – Load Raw Dataset\n",
    "\n",
    "In this step, we load the **final scraped CSV** from Phase 1 (`hellowork_final_sectors_data.csv`) into a pandas DataFrame for preprocessing.\n",
    "\n",
    "**Objectives:**\n",
    "- Inspect the dataset shape (number of rows and columns)\n",
    "- Verify column names\n",
    "- Preview the first few rows to understand the raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc7e268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1364, 8)\n",
      "\n",
      "Columns:\n",
      " Index(['Sector', 'Job_Title', 'Company', 'Location', 'Contract', 'Salary',\n",
      "       'Description', 'URL'],\n",
      "      dtype='object')\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sector</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Contract</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agriculture • Pêche</td>\n",
       "      <td>Alternance - Chargé·e de Formation H/F</td>\n",
       "      <td>Remy Cointreau</td>\n",
       "      <td>Paris - 75</td>\n",
       "      <td>Alternance</td>\n",
       "      <td>486,49 - 1 801,80 € / mois</td>\n",
       "      <td>Nous recherchons un·e candidat·e :  Alternance...</td>\n",
       "      <td>https://www.hellowork.com/fr-fr/emplois/642118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTP</td>\n",
       "      <td>Electricien H/F</td>\n",
       "      <td>Samsic Emploi</td>\n",
       "      <td>Rennes - 35</td>\n",
       "      <td>Intérim</td>\n",
       "      <td>12 - 15 € / heure</td>\n",
       "      <td>Nous recherchons activement un/une electricien...</td>\n",
       "      <td>https://www.hellowork.com/fr-fr/emplois/729658...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BTP</td>\n",
       "      <td>Ouvrier Polyvalent en Menuiserie H/F</td>\n",
       "      <td>Groupe Actual</td>\n",
       "      <td>Auterive - 31</td>\n",
       "      <td>Intérim</td>\n",
       "      <td>Estimation → 12,36 - 13,50 € / heure</td>\n",
       "      <td>Nous recherchons un(e) menuisier(e) expériment...</td>\n",
       "      <td>https://www.hellowork.com/fr-fr/emplois/732798...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BTP</td>\n",
       "      <td>Stagiaire Ressources Humaines 44 H/F</td>\n",
       "      <td>Equans France</td>\n",
       "      <td>Le Bignon - 44</td>\n",
       "      <td>Stage</td>\n",
       "      <td>Pas de salaire renseigné</td>\n",
       "      <td>Description de l'emploi: Au quotidien, Bouygue...</td>\n",
       "      <td>https://www.hellowork.com/fr-fr/emplois/730495...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BTP</td>\n",
       "      <td>Manutentionnaire - Job Étudiant H/F</td>\n",
       "      <td>Crit</td>\n",
       "      <td>Terssac - 81</td>\n",
       "      <td>Intérim</td>\n",
       "      <td>13 € / heure</td>\n",
       "      <td>Dans le cadre du développement de son activité...</td>\n",
       "      <td>https://www.hellowork.com/fr-fr/emplois/730409...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Sector                               Job_Title  \\\n",
       "0  Agriculture • Pêche  Alternance - Chargé·e de Formation H/F   \n",
       "1                  BTP                         Electricien H/F   \n",
       "2                  BTP    Ouvrier Polyvalent en Menuiserie H/F   \n",
       "3                  BTP    Stagiaire Ressources Humaines 44 H/F   \n",
       "4                  BTP     Manutentionnaire - Job Étudiant H/F   \n",
       "\n",
       "          Company        Location    Contract  \\\n",
       "0  Remy Cointreau      Paris - 75  Alternance   \n",
       "1   Samsic Emploi     Rennes - 35     Intérim   \n",
       "2   Groupe Actual   Auterive - 31     Intérim   \n",
       "3   Equans France  Le Bignon - 44       Stage   \n",
       "4            Crit    Terssac - 81     Intérim   \n",
       "\n",
       "                                 Salary  \\\n",
       "0            486,49 - 1 801,80 € / mois   \n",
       "1                     12 - 15 € / heure   \n",
       "2  Estimation → 12,36 - 13,50 € / heure   \n",
       "3              Pas de salaire renseigné   \n",
       "4                          13 € / heure   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Nous recherchons un·e candidat·e :  Alternance...   \n",
       "1  Nous recherchons activement un/une electricien...   \n",
       "2  Nous recherchons un(e) menuisier(e) expériment...   \n",
       "3  Description de l'emploi: Au quotidien, Bouygue...   \n",
       "4  Dans le cadre du développement de son activité...   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.hellowork.com/fr-fr/emplois/642118...  \n",
       "1  https://www.hellowork.com/fr-fr/emplois/729658...  \n",
       "2  https://www.hellowork.com/fr-fr/emplois/732798...  \n",
       "3  https://www.hellowork.com/fr-fr/emplois/730495...  \n",
       "4  https://www.hellowork.com/fr-fr/emplois/730409...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Step 1: Load Raw Dataset ---\n",
    "# Load the final scraped CSV from Phase 1\n",
    "df = pd.read_csv(\"hellowork_final_sectors_data.csv\", encoding='utf-8-sig')\n",
    "\n",
    "# Inspect basic info\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumns:\\n\", df.columns)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f5b93d",
   "metadata": {},
   "source": [
    "## Step 2 – Handle Missing Values and Duplicates\n",
    "\n",
    "Before processing the dataset for analysis or ML, we need to **clean it**:\n",
    "\n",
    "**Objectives:**\n",
    "- Remove duplicate rows to ensure data consistency.\n",
    "- Identify and handle missing values in key columns:\n",
    "  - `Job_Title`, `Company`, `Location`, `Contract`, `Salary`, `Description`\n",
    "- Fill missing values with placeholders (`\"Not specified\"` for text, `NaN` for numeric) to maintain consistency.\n",
    "\n",
    "This ensures the dataset is **clean, complete, and ready for further preprocessing**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b1c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Handle Missing Values and Duplicates ---\n",
    "\n",
    "# 1. Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "print(f\"After removing duplicates, dataset shape: {df.shape}\")\n",
    "\n",
    "# 2. Handle missing values\n",
    "text_columns = [\"Job_Title\", \"Company\", \"Location\", \"Contract\", \"Description\"]\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].fillna(\"Not specified\")\n",
    "\n",
    "# For Salary, leave as NaN for now (we'll process it in Step 3)\n",
    "df['Salary'] = pd.to_numeric(df['Salary'].str.replace(r'[^\\d]', '', regex=True), errors='coerce')\n",
    "\n",
    "# 3. Check remaining missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d719f0",
   "metadata": {},
   "source": [
    "## Step 3 – Standardize Salaries\n",
    "\n",
    "Job postings may have **salaries in various formats** (monthly, annual, ranges, or text).  \n",
    "We need to **extract numeric values** and standardize them into a **common unit**, e.g., **monthly salary in EUR**.\n",
    "\n",
    "**Objectives:**\n",
    "- Remove non-numeric characters from salary strings\n",
    "- Handle ranges by taking the average\n",
    "- Convert annual salaries to monthly if indicated\n",
    "- Keep missing salaries as NaN for ML handling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ed8b25",
   "metadata": {},
   "source": [
    "# --- Step 3: Standardize Salaries ---\n",
    "\n",
    "def clean_salary(salary_str):\n",
    "    \"\"\"\n",
    "    Extract numeric salary value and standardize it.\n",
    "    Assumes:\n",
    "    - Monthly salary if not specified\n",
    "    - Average for ranges\n",
    "    \"\"\"\n",
    "    if pd.isna(salary_str) or salary_str == \"Not specified\":\n",
    "        return np.nan\n",
    "    # Remove non-digit characters\n",
    "    numbers = re.findall(r'\\d+', salary_str.replace(\" \", \"\"))\n",
    "    numbers = [int(n) for n in numbers]\n",
    "    if len(numbers) == 0:\n",
    "        return np.nan\n",
    "    elif len(numbers) == 1:\n",
    "        return numbers[0]\n",
    "    else:\n",
    "        # If range, return average\n",
    "        return sum(numbers)/len(numbers)\n",
    "\n",
    "# Apply cleaning function\n",
    "df['Salary_Clean'] = df['Salary'].astype(str).apply(clean_salary)\n",
    "\n",
    "# Inspect cleaned salary column\n",
    "print(df[['Salary', 'Salary_Clean']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fadbe5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Salary  Salary_Clean\n",
      "0  4.864918e+10  2.432459e+10\n",
      "1  1.215000e+03  6.075000e+02\n",
      "2  1.236135e+07  6.180675e+06\n",
      "3           NaN           NaN\n",
      "4  1.300000e+01  6.500000e+00\n",
      "5  4.864918e+10  2.432459e+10\n",
      "6  1.315000e+03  6.575000e+02\n",
      "7  1.188000e+03  5.940000e+02\n",
      "8  1.900250e+07  9.501250e+06\n",
      "9           NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Standardize Salaries ---\n",
    "\n",
    "def clean_salary(salary_str):\n",
    "    \"\"\"\n",
    "    Extract numeric salary value and standardize it.\n",
    "    Assumes:\n",
    "    - Monthly salary if not specified\n",
    "    - Average for ranges\n",
    "    \"\"\"\n",
    "    if pd.isna(salary_str) or salary_str == \"Not specified\":\n",
    "        return np.nan\n",
    "    # Remove non-digit characters\n",
    "    numbers = re.findall(r'\\d+', salary_str.replace(\" \", \"\"))\n",
    "    numbers = [int(n) for n in numbers]\n",
    "    if len(numbers) == 0:\n",
    "        return np.nan\n",
    "    elif len(numbers) == 1:\n",
    "        return numbers[0]\n",
    "    else:\n",
    "        # If range, return average\n",
    "        return sum(numbers)/len(numbers)\n",
    "\n",
    "# Apply cleaning function\n",
    "df['Salary_Clean'] = df['Salary'].astype(str).apply(clean_salary)\n",
    "\n",
    "# Inspect cleaned salary column\n",
    "print(df[['Salary', 'Salary_Clean']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c7215",
   "metadata": {},
   "source": [
    "## Step 4 – Text Preprocessing for Job Descriptions\n",
    "\n",
    "Job descriptions are **raw text**, containing punctuation, stopwords, and inconsistent formatting.  \n",
    "For **clustering or classification**, we need to **clean and tokenize** them.\n",
    "\n",
    "**Objectives:**\n",
    "- Convert text to **lowercase**\n",
    "- Remove **punctuation and special characters**\n",
    "- Remove **stopwords** (common words with little meaning)\n",
    "- Optional: Lemmatization or stemming for further normalization\n",
    "- Prepare a **cleaned text column** for vectorization in Phase 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f425905c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\faleg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Description_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nous recherchons un·e candidat·e :  Alternance...</td>\n",
       "      <td>recherchons un·e candidat·e alternance chargé·...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nous recherchons activement un/une electricien...</td>\n",
       "      <td>recherchons activement unune electriciennne ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nous recherchons un(e) menuisier(e) expériment...</td>\n",
       "      <td>recherchons menuisiere expérimentée rejoindre ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Description de l'emploi: Au quotidien, Bouygue...</td>\n",
       "      <td>description lemploi quotidien bouygues energie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dans le cadre du développement de son activité...</td>\n",
       "      <td>cadre développement activité recherchons clien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0  Nous recherchons un·e candidat·e :  Alternance...   \n",
       "1  Nous recherchons activement un/une electricien...   \n",
       "2  Nous recherchons un(e) menuisier(e) expériment...   \n",
       "3  Description de l'emploi: Au quotidien, Bouygue...   \n",
       "4  Dans le cadre du développement de son activité...   \n",
       "\n",
       "                                   Description_Clean  \n",
       "0  recherchons un·e candidat·e alternance chargé·...  \n",
       "1  recherchons activement unune electriciennne ca...  \n",
       "2  recherchons menuisiere expérimentée rejoindre ...  \n",
       "3  description lemploi quotidien bouygues energie...  \n",
       "4  cadre développement activité recherchons clien...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Step 4: Text Preprocessing ---\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Download stopwords if not already\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('french'))  # Using French stopwords\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # lowercase\n",
    "    text = text.replace(\"\\n\", \" \").strip()  # remove line breaks\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # remove punctuation\n",
    "    tokens = [word for word in text.split() if word not in stop_words]  # remove stopwords\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply cleaning\n",
    "df['Description_Clean'] = df['Description'].apply(clean_text)\n",
    "\n",
    "# Inspect cleaned descriptions\n",
    "df[['Description', 'Description_Clean']].head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48c1297",
   "metadata": {},
   "source": [
    "## Step 5 – Encode Categorical Variables\n",
    "\n",
    "Many columns (e.g., `Contract`, `Location`, `Sector`) are **categorical** and need to be **encoded numerically** for ML algorithms.\n",
    "\n",
    "**Objectives:**\n",
    "- Convert categorical columns into **numeric representations** using one-hot encoding or label encoding\n",
    "- Keep original columns for filtering in dashboards if needed\n",
    "- Prepare dataset for clustering and classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57c542c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contract</th>\n",
       "      <th>Contract_Encoded</th>\n",
       "      <th>Location</th>\n",
       "      <th>Location_Encoded</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Sector_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alternance</td>\n",
       "      <td>0</td>\n",
       "      <td>Paris - 75</td>\n",
       "      <td>452</td>\n",
       "      <td>Agriculture • Pêche</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Intérim</td>\n",
       "      <td>4</td>\n",
       "      <td>Rennes - 35</td>\n",
       "      <td>493</td>\n",
       "      <td>BTP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intérim</td>\n",
       "      <td>4</td>\n",
       "      <td>Auterive - 31</td>\n",
       "      <td>24</td>\n",
       "      <td>BTP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stage</td>\n",
       "      <td>6</td>\n",
       "      <td>Le Bignon - 44</td>\n",
       "      <td>332</td>\n",
       "      <td>BTP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intérim</td>\n",
       "      <td>4</td>\n",
       "      <td>Terssac - 81</td>\n",
       "      <td>582</td>\n",
       "      <td>BTP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Contract  Contract_Encoded        Location  Location_Encoded  \\\n",
       "0  Alternance                 0      Paris - 75               452   \n",
       "1     Intérim                 4     Rennes - 35               493   \n",
       "2     Intérim                 4   Auterive - 31                24   \n",
       "3       Stage                 6  Le Bignon - 44               332   \n",
       "4     Intérim                 4    Terssac - 81               582   \n",
       "\n",
       "                Sector  Sector_Encoded  \n",
       "0  Agriculture • Pêche               0  \n",
       "1                  BTP               1  \n",
       "2                  BTP               1  \n",
       "3                  BTP               1  \n",
       "4                  BTP               1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Step 5: Encode Categorical Variables ---\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Columns to encode\n",
    "categorical_cols = ['Contract', 'Location', 'Sector']\n",
    "\n",
    "# Apply Label Encoding\n",
    "le_dict = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col + '_Encoded'] = le.fit_transform(df[col])\n",
    "    le_dict[col] = le  # Save encoder for future inverse_transform if needed\n",
    "\n",
    "# Inspect encoding\n",
    "df[['Contract', 'Contract_Encoded', 'Location', 'Location_Encoded', 'Sector', 'Sector_Encoded']].head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7fb3f6",
   "metadata": {},
   "source": [
    "## Step 6 – Feature Extraction from Job Descriptions\n",
    "\n",
    "To enrich the dataset for ML models, we extract **important keywords or skills** from job descriptions.\n",
    "\n",
    "**Objectives:**\n",
    "- Identify the most frequent words or terms in job descriptions\n",
    "- Optionally, extract **skills or key phrases** using simple frequency-based methods or TF-IDF\n",
    "- Create additional features for clustering or classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2638fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF feature matrix shape: (1244, 500)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>10h</th>\n",
       "      <th>13h</th>\n",
       "      <th>1418</th>\n",
       "      <th>14h</th>\n",
       "      <th>15</th>\n",
       "      <th>18h</th>\n",
       "      <th>23</th>\n",
       "      <th>2h</th>\n",
       "      <th>35</th>\n",
       "      <th>...</th>\n",
       "      <th>équipe</th>\n",
       "      <th>équipes</th>\n",
       "      <th>éthique</th>\n",
       "      <th>études</th>\n",
       "      <th>étudiant</th>\n",
       "      <th>étudiante</th>\n",
       "      <th>étudiantrémunération</th>\n",
       "      <th>étudiants</th>\n",
       "      <th>évoluer</th>\n",
       "      <th>être</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.252615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         10  10h  13h  1418  14h   15  18h   23   2h   35  ...    équipe  \\\n",
       "0  0.000000  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "1  0.000000  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "2  0.000000  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.138837   \n",
       "3  0.000000  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.056201   \n",
       "4  0.252615  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "\n",
       "    équipes  éthique  études  étudiant  étudiante  étudiantrémunération  \\\n",
       "0  0.085515      0.0     0.0  0.000000   0.000000                   0.0   \n",
       "1  0.000000      0.0     0.0  0.000000   0.000000                   0.0   \n",
       "2  0.000000      0.0     0.0  0.000000   0.000000                   0.0   \n",
       "3  0.000000      0.0     0.0  0.000000   0.075646                   0.0   \n",
       "4  0.000000      0.0     0.0  0.108104   0.000000                   0.0   \n",
       "\n",
       "   étudiants  évoluer  être  \n",
       "0   0.000000      0.0   0.0  \n",
       "1   0.000000      0.0   0.0  \n",
       "2   0.199516      0.0   0.0  \n",
       "3   0.000000      0.0   0.0  \n",
       "4   0.000000      0.0   0.0  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Step 6: Feature Extraction from Text ---\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF vectorizer with list of stopwords\n",
    "tfidf = TfidfVectorizer(max_features=500, stop_words=list(stop_words))  # Convert set to list\n",
    "\n",
    "# Fit and transform the cleaned descriptions\n",
    "tfidf_matrix = tfidf.fit_transform(df['Description_Clean'])\n",
    "\n",
    "# Convert to DataFrame for inspection\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
    "print(\"TF-IDF feature matrix shape:\", tfidf_df.shape)\n",
    "tfidf_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237f929f",
   "metadata": {},
   "source": [
    "## Step 7 – Save the Preprocessed Dataset\n",
    "\n",
    "After cleaning salaries, preprocessing text, and encoding categorical variables, we save the dataset for **Phase 3 (ML)**.\n",
    "\n",
    "**Objectives:**\n",
    "- Ensure all preprocessing is persisted\n",
    "- Avoid repeating costly preprocessing\n",
    "- Use a clear file naming convention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf3d6100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset saved to hellowork_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Step 7: Save Preprocessed Dataset ---\n",
    "\n",
    "preprocessed_filename = \"hellowork_preprocessed.csv\"\n",
    "df.to_csv(preprocessed_filename, index=False, encoding='utf-8-sig')\n",
    "print(f\"Preprocessed dataset saved to {preprocessed_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac348947",
   "metadata": {},
   "source": [
    "## Step 8 – Summary of Phase 2 ETL\n",
    "\n",
    "Phase 2 focused on **cleaning, transforming, and structuring** the raw scraped data:\n",
    "\n",
    "1. **Load Raw Data** from Phase 1 CSV\n",
    "2. **Inspect Dataset** structure and columns\n",
    "3. **Standardize Salaries** into numeric monthly values\n",
    "4. **Preprocess Text** in job descriptions (lowercase, remove punctuation & stopwords)\n",
    "5. **Encode Categorical Variables** for ML models\n",
    "6. **Extract Features** from job descriptions using TF-IDF\n",
    "7. **Save Preprocessed Dataset** for modeling\n",
    "\n",
    "**Result:**  \n",
    "A clean, structured, and ML-ready dataset with numeric and textual features, ready for **clustering, classification, and enrichment** in Phase 3.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
